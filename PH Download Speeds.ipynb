{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc73ab65",
   "metadata": {},
   "source": [
    "# PH Download Speeds\n",
    "\n",
    "This data project's overall goal is to identify cities or municipalities in the Philippines with a good internet connection and potentially be a location for a work-from-home setup. \n",
    "\n",
    "There are two primary steps: the data prep and the visualization step. This notebook will focus on the data prep. \n",
    "\n",
    "Key steps in the data preprocessing:\n",
    "1. Join the data from [Speedtest by Ookla](https://registry.opendata.aws/speedtest-global-performance/) and join it with the Philippine boundaries data from [HDX](https://data.humdata.org/dataset/philippines-administrative-levels-0-to-3) \n",
    "2. Aggregate the data to the city/town level and add speed brackets and other data \n",
    "3. Export the data to a shp file that is to be visualized in Tableau \n",
    "\n",
    "The data preprocessing stage is heavily lifted from [katiejolly-ookla](https://github.com/teamookla/ookla-open-data/blob/master/tutorials/aggregate_by_county_py.ipynb).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a851de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import geopandas as gp\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from shapely.geometry import Point\n",
    "from adjustText import adjust_text\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fdc67d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://ookla-open-data.s3-us-west-2.amazonaws.com/shapefiles/performance/type%3Dmobile/year%3D2021/quarter%3D1/2021-01-01_performance_mobile_tiles.zip'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quarter_start(year: int, q: int) -> datetime:\n",
    "    if not 1 <= q <= 4:\n",
    "        raise ValueError(\"Quarter must be within [1, 2, 3, 4]\")\n",
    "\n",
    "    month = [1, 4, 7, 10]\n",
    "    return datetime(year, month[q - 1], 1)\n",
    "\n",
    "\n",
    "def get_tile_url(service_type: str, year: int, q: int) -> str:\n",
    "    dt = quarter_start(year, q)\n",
    "\n",
    "    base_url = \"https://ookla-open-data.s3-us-west-2.amazonaws.com/shapefiles/performance\"\n",
    "    url = f\"{base_url}/type%3D{service_type}/year%3D{dt:%Y}/quarter%3D{q}/{dt:%Y-%m-%d}_performance_{service_type}_tiles.zip\"\n",
    "    return url\n",
    "\n",
    "tile_url = get_tile_url(\"mobile\", 2021, 1)\n",
    "tile_url"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20db522",
   "metadata": {},
   "source": [
    "## Downloading and joining the necessary files\n",
    "\n",
    "You can directly read the files from the website. However, I chose to download the files to my local machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a1d2a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "curd = os.getcwd()\n",
    "tiles = gp.read_file(curd+'/downloads/2021-01-01_performance_mobile_tiles.zip')\n",
    "fixed = gp.read_file(curd+'/downloads/2021-01-01_performance_fixed_tiles.zip')\n",
    "counties = gp.read_file(curd+'/downloads/admin3.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ef6d5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_in_cities = gp.sjoin(counties, tiles, how='left', op='intersects')\n",
    "fixed_in_cities = gp.sjoin(counties, fixed, how='left', op='intersects')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d01102",
   "metadata": {},
   "source": [
    "## Aggregating and adding speed brackets and other data\n",
    "\n",
    "For the visualizaion step, I had to have the data aggregated to the cities/town level due to file size consideration. Also, I had to add labels, speed brackets, convert the unit of measurement etc. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a6c8801",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiles_in_cities['con_type'] = 'mobile'\n",
    "fixed_in_cities['con_type'] = 'fixed'\n",
    "ph_net_speeds = pd.concat([tiles_in_cities,fixed_in_cities])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "313af67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph_net_speeds['avg_d_mbps'] = ph_net_speeds['avg_d_kbps'] / 1000\n",
    "ph_net_speeds['avg_u_mbps'] = ph_net_speeds['avg_u_kbps'] / 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a2db65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"0 to 5 Mbps\", \"5 to 10 Mbps\", \"10 to 15 Mbps\", \"15 to 25 Mbps\", \"25 to 200 Mbps\"]\n",
    "\n",
    "ph_net_speeds['group'] = pd.cut(\n",
    "    ph_net_speeds.avg_d_mbps, \n",
    "    (0, 5, 10, 15, 25, 200), \n",
    "    right=False, \n",
    "    labels = labels\n",
    ")\n",
    "\n",
    "# Subset the data for aggregation \n",
    "ph_contri = ph_net_speeds[['ADM3_PCODE','ADM3_EN','con_type','group','tests']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c359f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the data at the speed bracket level. This will be used to calculate the % contribution of tests \n",
    "z_group = ph_contri\n",
    "z_group = z_group.groupby(['ADM3_PCODE','con_type','group'])\\\n",
    ".agg({\"tests\" : \"sum\"})[[\"tests\"]]\n",
    "z_group = z_group.reset_index()\n",
    "\n",
    "# aggregate the data at the connection type level\n",
    "p_cont_type = ph_contri.groupby(['ADM3_PCODE','con_type'])\\\n",
    ".agg({\"tests\" : \"sum\"})[[\"tests\"]]\n",
    "# https://stackoverflow.com/questions/10373660/converting-a-pandas-groupby-output-from-series-to-dataframe\n",
    "p_con_type = p_cont_type.add_suffix('_total').reset_index()\n",
    "\n",
    "# combine the aggregations to \n",
    "result = pd.merge(left=z_group, right=p_con_type,\\\n",
    "                  left_on=['ADM3_PCODE','con_type'], right_on=['ADM3_PCODE','con_type'])\n",
    "\n",
    "# calculate the % contribution and pivot the data\n",
    "result['perc_cont'] = result.tests/result.tests_total*100\n",
    "result = pd.pivot_table(result, values = 'perc_cont', index=['ADM3_PCODE', 'con_type'], columns = 'group')\n",
    "result = result.add_suffix('_contri').reset_index()\n",
    "speed_distro = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45e52d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the totals for tests, avg speed, and device count  \n",
    "county_stats = (\n",
    "    ph_net_speeds.groupby([\"ADM3_EN\",\"ADM3_PCODE\",\"con_type\"])\n",
    "    .apply(\n",
    "        lambda x: pd.Series(\n",
    "            {\"avg_d_mbps_wt\": np.average(x[\"avg_d_mbps\"], weights=x[\"tests\"])}\n",
    "        )\n",
    "    )\n",
    "    .reset_index()\n",
    "    .merge(\n",
    "        ph_net_speeds.groupby([\"ADM3_EN\",\"ADM3_PCODE\",\"con_type\"])\n",
    "        .agg(tests=(\"tests\", \"sum\"),devices=(\"devices\",\"sum\"))\n",
    "        .reset_index(),\n",
    "        on=[\"ADM3_EN\",\"ADM3_PCODE\",\"con_type\"],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1392ee",
   "metadata": {},
   "source": [
    "## Combine all the aggregations to one dataframe and export to a shp file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "856b34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-646b40f460fe>:4: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  to_tab.to_file(curd+'/downloads/ph_net_speeds.shp')\n"
     ]
    }
   ],
   "source": [
    "to_tab = pd.merge(left=county_stats, right=speed_distro,\\\n",
    "                  left_on=['ADM3_PCODE','con_type'], right_on=['ADM3_PCODE','con_type'])\n",
    "to_tab = pd.merge(left=counties, right=to_tab, left_on=['ADM3_PCODE'], right_on=['ADM3_PCODE'])\n",
    "to_tab.to_file(curd+'/downloads/ph_net_speeds.shp')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
